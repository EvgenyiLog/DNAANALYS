{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d746f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "uint16\n",
      "(2866, 2944)\n",
      "image min =295\n",
      "image max =3917\n",
      "image mean =638.147935337275\n",
      "image std =122.52519577460907\n",
      "\n",
      "Hue=0\n",
      "Saturation=1035816653\n",
      "Lightness =0\n",
      "Lightness min =0\n",
      "Lightness max =0\n",
      "Lightness mean =0.0\n",
      "Lightness std =0.0\n",
      "Hue=0\n",
      "Saturation=0\n",
      "Value  =1035816653\n",
      "Value min =0\n",
      "Value max =255\n",
      "Value mean =122.76339697142662\n",
      "Value std =71.35964813926628\n",
      "image min =0\n",
      "image max =255\n",
      "image mean =122.76339697142662\n",
      "image std =71.35964813926623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_39300\\1807071372.py:496: UserWarning: Inputs have mismatched dtype.  Setting data_range based on image_true.\n",
      "  psnr=peak_signal_noise_ratio(imagepsnr, std_convoluted(imagepsnr,2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR before filtration=8.383048314233271\n",
      "PSNR before filtration=-37.069053999011615\n",
      "PSNR before filtration max std=11.061749609667489\n",
      "uint8\n",
      "mse\n",
      "2921.032034947776\n",
      "ssim\n",
      "0.01734035162962039\n",
      "\n",
      "(2866, 2944)\n",
      "(2866, 2944)\n",
      "\n",
      "(5731, 5887)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_39300\\1807071372.py:615: UserWarning: Inputs have mismatched dtype.  Setting data_range based on image_true.\n",
      "  psnr=peak_signal_noise_ratio(hlpfilt, std_convoluted(hlpfilt,2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR after filtration=0.5363691264555567\n",
      "PSNR after filtration=-36.04339732051369\n",
      "PSNR after filtration max std=12.087406288165415\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 2944)]            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8192)              24125440  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2944)              24120192  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,245,632\n",
      "Trainable params: 48,245,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 7s 908ms/step - loss: 16171.7002\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 6s 1s/step - loss: 16087.1084\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 6s 937ms/step - loss: 16012.4971\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 5s 824ms/step - loss: 15944.9502\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 5s 812ms/step - loss: 15882.4971\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 5s 806ms/step - loss: 15823.8047\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 5s 829ms/step - loss: 15767.9902\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 5s 813ms/step - loss: 15714.4023\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 5s 834ms/step - loss: 15662.4678\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 5s 801ms/step - loss: 15611.8838\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 5s 806ms/step - loss: 15562.3096\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 5s 810ms/step - loss: 15513.4600\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 5s 868ms/step - loss: 15465.3594\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 6s 990ms/step - loss: 15417.8916\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 6s 984ms/step - loss: 15371.0449\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 5s 856ms/step - loss: 15325.0625\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 5s 831ms/step - loss: 15280.1426\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 5s 852ms/step - loss: 15236.4141\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 5s 843ms/step - loss: 15193.8926\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 5s 872ms/step - loss: 15152.8965\n",
      "90/90 [==============================] - 2s 18ms/step\n",
      "Количество\n",
      "982228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from libtiff import TIFF\n",
    "from skimage import io\n",
    "#import pytiff\n",
    "from tifffile import tifffile\n",
    "#import OpenImageIO as oiio\n",
    "#import rasterio\n",
    "#import tensorflow_io as tfio\n",
    "import cv2\n",
    "import scipy\n",
    "import keras\n",
    "from skimage import color, data, restoration\n",
    "from scipy.signal import convolve2d\n",
    "import sporco\n",
    "import skimage \n",
    "from scipy import ndimage\n",
    "from skimage import measure\n",
    "import matlab\n",
    "import matlab.engine \n",
    "from wolframclient.evaluation import WolframLanguageSession\n",
    "from wolframclient.language import wl\n",
    "from wolframclient.language import wl, wlexpr\n",
    "from wolframclient.evaluation import WolframLanguageSession \n",
    "#import htmlPy\n",
    "import eel\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import mean_squared_error\n",
    "from skimage import filters\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage import morphology\n",
    "import pandas as pd\n",
    "from pyclesperanto_prototype import imshow\n",
    "import pyclesperanto_prototype as cle\n",
    "from skimage.io import imread\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import hessian\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "import pandas as pd\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.lines import Line2D\n",
    "#import sunkit_image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def boxplot_2d(x,y, ax, whis=1.5):\n",
    "    xlimits = [np.percentile(x, q) for q in (25, 50, 75)]\n",
    "    ylimits = [np.percentile(y, q) for q in (25, 50, 75)]\n",
    "\n",
    "    ##the box\n",
    "    box = Rectangle(\n",
    "        (xlimits[0],ylimits[0]),\n",
    "        (xlimits[2]-xlimits[0]),\n",
    "        (ylimits[2]-ylimits[0]),\n",
    "        ec = 'k',\n",
    "        zorder=0\n",
    "    )\n",
    "    ax.add_patch(box)\n",
    "\n",
    "    ##the x median\n",
    "    vline = Line2D(\n",
    "        [xlimits[1],xlimits[1]],[ylimits[0],ylimits[2]],\n",
    "        color='k',\n",
    "        zorder=1\n",
    "    )\n",
    "    ax.add_line(vline)\n",
    "\n",
    "    ##the y median\n",
    "    hline = Line2D(\n",
    "        [xlimits[0],xlimits[2]],[ylimits[1],ylimits[1]],\n",
    "        color='k',\n",
    "        zorder=1\n",
    "    )\n",
    "    ax.add_line(hline)\n",
    "\n",
    "    ##the central point\n",
    "    ax.plot([xlimits[1]],[ylimits[1]], color='k', marker='o')\n",
    "\n",
    "    ##the x-whisker\n",
    "    ##defined as in matplotlib boxplot:\n",
    "    ##As a float, determines the reach of the whiskers to the beyond the\n",
    "    ##first and third quartiles. In other words, where IQR is the\n",
    "    ##interquartile range (Q3-Q1), the upper whisker will extend to\n",
    "    ##last datum less than Q3 + whis*IQR). Similarly, the lower whisker\n",
    "    ####will extend to the first datum greater than Q1 - whis*IQR. Beyond\n",
    "    ##the whiskers, data are considered outliers and are plotted as\n",
    "    ##individual points. Set this to an unreasonably high value to force\n",
    "    ##the whiskers to show the min and max values. Alternatively, set this\n",
    "    ##to an ascending sequence of percentile (e.g., [5, 95]) to set the\n",
    "    ##whiskers at specific percentiles of the data. Finally, whis can\n",
    "    ##be the string 'range' to force the whiskers to the min and max of\n",
    "    ##the data.\n",
    "    iqr = xlimits[2]-xlimits[0]\n",
    "\n",
    "    ##left\n",
    "    left = np.min(x[x > xlimits[0]-whis*iqr])\n",
    "    whisker_line = Line2D(\n",
    "        [left, xlimits[0]], [ylimits[1],ylimits[1]],\n",
    "        color = 'k',\n",
    "        zorder = 1\n",
    "    )\n",
    "    ax.add_line(whisker_line)\n",
    "    whisker_bar = Line2D(\n",
    "        [left, left], [ylimits[0],ylimits[2]],\n",
    "        color = 'k',\n",
    "        zorder = 1\n",
    "    )\n",
    "    ax.add_line(whisker_bar)\n",
    "\n",
    "    ##right\n",
    "    right = np.max(x[x < xlimits[2]+whis*iqr])\n",
    "    whisker_line = Line2D(\n",
    "        [right, xlimits[2]], [ylimits[1],ylimits[1]],\n",
    "        color = 'k',\n",
    "        zorder = 1\n",
    "    )\n",
    "    ax.add_line(whisker_line)\n",
    "    whisker_bar = Line2D(\n",
    "        [right, right], [ylimits[0],ylimits[2]],\n",
    "        color = 'k',\n",
    "        zorder = 1\n",
    "    )\n",
    "    ax.add_line(whisker_bar)\n",
    "\n",
    "    ##the y-whisker\n",
    "    iqr = ylimits[2]-ylimits[0]\n",
    "\n",
    "    ##bottom\n",
    "    bottom = np.min(y[y > ylimits[0]-whis*iqr])\n",
    "    whisker_line = Line2D(\n",
    "        [xlimits[1],xlimits[1]], [bottom, ylimits[0]], \n",
    "        color = 'k',\n",
    "        zorder = 1\n",
    "    )\n",
    "    ax.add_line(whisker_line)\n",
    "    whisker_bar = Line2D(\n",
    "        [xlimits[0],xlimits[2]], [bottom, bottom], \n",
    "        color = 'k',\n",
    "        zorder = 1\n",
    "    )\n",
    "    ax.add_line(whisker_bar)\n",
    "\n",
    "    ##top\n",
    "    top = np.max(y[y < ylimits[2]+whis*iqr])\n",
    "    whisker_line = Line2D(\n",
    "        [xlimits[1],xlimits[1]], [top, ylimits[2]], \n",
    "        color = 'k',\n",
    "        zorder = 1\n",
    "    )\n",
    "    ax.add_line(whisker_line)\n",
    "    whisker_bar = Line2D(\n",
    "        [xlimits[0],xlimits[2]], [top, top], \n",
    "        color = 'k',\n",
    "        zorder = 1\n",
    "    )\n",
    "    ax.add_line(whisker_bar)\n",
    "\n",
    "    ##outliers\n",
    "    mask = (x<left)|(x>right)|(y<bottom)|(y>top)\n",
    "    ax.scatter(\n",
    "        x[mask],y[mask],\n",
    "        facecolors='none', edgecolors='k'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def generate_feature_stack(image):\n",
    "    # determine features\n",
    "    blurred = filters.gaussian(image, sigma=2)\n",
    "    edges = filters.sobel(blurred)\n",
    "\n",
    "    # collect features in a stack\n",
    "    # The ravel() function turns a nD image into a 1-D image.\n",
    "    # We need to use it because scikit-learn expects values in a 1-D format here. \n",
    "    feature_stack = [\n",
    "        image.ravel(),\n",
    "        blurred.ravel(),\n",
    "        edges.ravel()\n",
    "    ]\n",
    "    \n",
    "    # return stack as numpy-array\n",
    "    return np.asarray(feature_stack)\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "\n",
    "def gamma_trans(img,gamma):\n",
    "    # Конкретный метод сначала нормализуется до 1, а затем гамма используется в качестве значения индекса, чтобы найти новое значение пикселя, а затем восстановить\n",
    "    gamma_table = [np.power(x/255.0,gamma)*255.0 for x in range(256)]\n",
    "    gamma_table = np.round(np.array(gamma_table)).astype(np.uint8)\n",
    "    # Реализация сопоставления использует функцию поиска в таблице Opencv\n",
    "    return cv2.LUT(img0,gamma_table)\n",
    "\n",
    "\n",
    "def std_convoluted(image, N):\n",
    "    im = np.array(image, dtype=float)\n",
    "    im2 = im**2\n",
    "    ones = np.ones(im.shape)\n",
    "    \n",
    "    kernel = np.ones((2*N+1, 2*N+1))\n",
    "    s = scipy.signal.convolve2d(im, kernel, mode=\"same\")\n",
    "    s2 = scipy.signal.convolve2d(im2, kernel, mode=\"same\")\n",
    "    ns = scipy.signal.convolve2d(ones, kernel, mode=\"same\")\n",
    "    \n",
    "    return np.sqrt((s2 - s**2 / ns) / ns)\n",
    "\n",
    "def laplacian_of_gaussian(image, sigma):\n",
    "    \"\"\"\n",
    "    Applies a Gaussian kernel to an image and the Laplacian afterwards.\n",
    "    \"\"\"\n",
    "    \n",
    "    # blur the image using a Gaussian kernel\n",
    "    intermediate_result = filters.gaussian(image, sigma)\n",
    "    \n",
    "    # apply the mexican hat filter (Laplacian)\n",
    "    result = filters.laplace(intermediate_result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def readimage(path):\n",
    "    'path to file'\n",
    "    'чтение файла возвращает изображение'\n",
    "    \n",
    "    image = cv2.imread(path,0)\n",
    "    #print(image.shape)\n",
    "    print(image.dtype)\n",
    "    return image\n",
    "\n",
    "def tiffreader(path):\n",
    "    image=cv2.imread(path,-1)\n",
    "    #print(image.shape)\n",
    "    print(image.dtype)\n",
    "    return image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from matplotlib import cm\n",
    "def imageplot3d(image):\n",
    "    #x = np.linspace(0, image.shape[1], image.shape[1])\n",
    "    #y = np.linspace(0, image.shape[0], image.shape[0])\n",
    "    # full coordinate arrays\n",
    "    #xx, yy = np.meshgrid(x, y)\n",
    "    xx, yy = np.ogrid[0:image.shape[0],0:image.shape[1]]\n",
    "    fig = plt.figure(figsize=(15,7))          #create a canvas, tell matplotlib it's 3d\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    #ax.scatter(xs = xx, ys = yy, zs = image)\n",
    "    ax.plot_surface(xx,yy,image)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "from prettytable import PrettyTable\n",
    "from colorama import init, Fore, Back, Style     \n",
    "def localstdmean(image,N):\n",
    "    im = np.array(image, dtype=float)\n",
    "    im2 = im**2\n",
    "    ones = np.ones(im.shape)\n",
    "    \n",
    "    kernel = np.ones((2*N+1, 2*N+1))\n",
    "    s = scipy.signal.convolve2d(im, kernel, mode=\"same\")\n",
    "    s2 = scipy.signal.convolve2d(im2, kernel, mode=\"same\")\n",
    "    ns = scipy.signal.convolve2d(ones, kernel, mode=\"same\")\n",
    "    \n",
    "    noise=np.sqrt((s2 - s**2 / ns) / ns)\n",
    "    noise=np.asarray(noise,dtype=np.uint8)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(noise[0:1000,0:1000], cmap=plt.cm.gray,vmax=noise.max(),vmin=noise.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    noises=cv2.cvtColor(noise, cv2.COLOR_GRAY2BGR) \n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_noise.jpg\",noises)\n",
    "    background=scipy.signal.convolve2d(im, kernel, mode=\"same\")\n",
    "    background=np.asarray(background,dtype=np.uint8)\n",
    "    backgrounds=cv2.cvtColor( background, cv2.COLOR_GRAY2BGR) \n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_background.jpg\",backgrounds)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(background[0:1000,0:1000], cmap=plt.cm.gray,vmax=background.max(),vmin=background.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    \n",
    "    print(f'image min ={image.min()}')\n",
    "    print(f'image max ={image.max()}')\n",
    "    print(f'image mean ={image.mean()}')\n",
    "    print(f'image std ={image.std()}')\n",
    "\n",
    "from sklearn.decomposition import FastICA,PCA,KernelPCA\n",
    "def compresed(hlpfilt):\n",
    "    relative_rank = 0.9\n",
    "    max_rank = int(relative_rank * min(hlpfilt.shape[0], hlpfilt.shape[1]))\n",
    "    print(\"max rank = %d\" % max_rank)\n",
    "    U,S,VT=np.linalg.svd(hlpfilt)\n",
    "    A = np.zeros((U.shape[0], VT.shape[1]))\n",
    "    k=max_rank//2\n",
    "    for i in range(1,int(k)):\n",
    "        U_i = U[:,[i]]\n",
    "        VT_i = np.array([VT[i]])\n",
    "        A += S[i] * (U_i @ VT_i)\n",
    "    compressed_float=(U[:,:k] @ np.diag(S[:k])) @ VT[:k]\n",
    "    compressed = (np.minimum(compressed_float, 1.0) * 0xff).astype(np.uint8)\n",
    "    compreseds=cv2.cvtColor(compressed, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_compresedsvd.jpg\",compreseds)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(compressed[0:1000,0:1000],cmap='gray',vmax=compressed.max(),vmin=compressed.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    \n",
    "    pca = PCA(n_components=hlpfilt.shape[0]//2)\n",
    "    hlpfilt_new=pca.fit_transform(hlpfilt)\n",
    "    compresed=pca.inverse_transform(hlpfilt_new)\n",
    "    compreseds=cv2.cvtColor(compressed, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_compresedpca.jpg\",compreseds)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(compressed[0:1000,0:1000],cmap='gray',vmax=compressed.max(),vmin=compressed.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    fastica = FastICA(n_components=hlpfilt.shape[0]-1)\n",
    "    hlpfilt_new=fastica.fit_transform(hlpfilt)\n",
    "    compresed=fastica.inverse_transform(hlpfilt_new)\n",
    "    compreseds=cv2.cvtColor(compressed, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_compresedfastica.jpg\",compreseds)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(compresed[0:1000,0:1000],cmap='gray',vmax=compressed.max(),vmin=compressed.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    try:\n",
    "        transformer = KernelPCA(n_components=hlpfilt.shape[0]//2, kernel='rbf')\n",
    "        hlpfilt_new=transformer.fit_transform(hlpfilt)\n",
    "        compresed=transformer.inverse_transform(hlpfilt_new)\n",
    "        compreseds=cv2.cvtColor(compressed, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_compresedkernelpca.jpg\",compreseds)\n",
    "        plt.figure(figsize=(15,7))\n",
    "        plt.imshow(compresed[0:1000,0:1000],cmap='gray',vmax=compressed.max(),vmin=compressed.min())\n",
    "        #plt.grid(True)\n",
    "        plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "            \n",
    "def correlation_coefficient(patch1, patch2):\n",
    "    product = np.mean((patch1 - patch1.mean()) * (patch2 - patch2.mean()))\n",
    "    stds = patch1.std() * patch2.std()\n",
    "    if stds == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        product /= stds\n",
    "        return product\n",
    "\n",
    "\n",
    "def normcorr(image1,image2):\n",
    "    d = 1\n",
    "\n",
    "    correlation = np.zeros_like(image1)\n",
    "    sh_row, sh_col = image1.shape\n",
    "    for i in range(d, sh_row - (d + 1)):\n",
    "        for j in range(d, sh_col - (d + 1)):\n",
    "            correlation[i, j] = correlation_coefficient(image1[i - d: i + d + 1,j - d: j + d + 1],image2[i - d: i + d + 1,j - d: j + d + 1])\n",
    "\n",
    "    correlation=np.asarray(correlation,dtype=np.uint8)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(correlation[0:1000,0:1000],cmap='gray',vmax=correlation.max(),vmin=correlation.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    try:\n",
    "        r=cv2.cvtColor(correlation, cv2.COLOR_GRAY2BGR)\n",
    "    except:\n",
    "        r=correlation\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_a_normxcorr.jpg\",r)     \n",
    "\n",
    "def imageground(image):\n",
    "    # Вычисляем маску фона\n",
    "    image=np.uint8(image)\n",
    "    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Убираем шум\n",
    "    kernel = np.ones((2, 2), np.uint16)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=50)\n",
    "    background=opening\n",
    "    backgrounds=cv2.cvtColor( background, cv2.COLOR_GRAY2BGR) \n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_background1.jpg\",backgrounds)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(background[0:1000,0:1000], cmap=plt.cm.gray,vmax=background.max(),vmin=background.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "\n",
    "    # создаем маску фона\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=20) \n",
    "\n",
    "\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)  \n",
    "\n",
    "    foreground=sure_fg\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_foreground.jpg\",foreground)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(foreground[0:1000,0:1000], cmap=plt.cm.gray,vmax=foreground.max(),vmin=foreground.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "\n",
    "    # Вычисляем \"неопределенный регион\" из вычисленных фона и переднего плана\n",
    "    # В большинстве случаев это просто фон, т.к. передний план считается плохо.\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Размечаем маркеры. Они будут использованы для вычисления фона алгоритмом watershed\n",
    "    _, markers = cv2.connectedComponents(sure_fg)\n",
    "    # Добавляем единичку ко всем значениям, чтобы они были больше 0. Он отвечает за \"неизвестную\" область.\n",
    "    markers = markers + 1\n",
    "    # Добавляем \"неизвестную\" область на маркеры\n",
    "    #markers[unknown == 255] = 0\n",
    "\n",
    "    # собственно считаем\n",
    "    #markers = cv2.watershed(image, markers)\n",
    "    # и рисуем наши маркеры на изображении\n",
    "    #img[markers == -1] = [255, 0, 0]\n",
    "\n",
    "\n",
    "def process(img):\n",
    "    work_img = img.copy()\n",
    "\n",
    "    # считаем маску\n",
    "    _, threshold = cv2.threshold(work_img, 30, 200, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # ищем на маске контуры\n",
    "    contours, hierarchy = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_area = 0\n",
    "    max_contour = []\n",
    "\n",
    "    # ищем самый большой из найденных контуров\n",
    "    for cnt in contours:\n",
    "        approx = cv2.approxPolyDP(cnt, 0.1 * cv2.arcLength(cnt, True), True)\n",
    "\n",
    "        cnt_area = cv2.contourArea(cnt)\n",
    "        # обязательно проверяем кол-во точек.\n",
    "        # Иначе, часто, получается что самая большая фигура -\n",
    "        # это треугольник через всю диагональ изображения\n",
    "        if len(approx) > 3 and cnt_area > max_area:\n",
    "            max_area = cnt_area\n",
    "            max_contour = approx\n",
    "\n",
    "    # рисуем самый большой контур на изображении\n",
    "    cv2.drawContours(work_img, [max_contour], 0, (255, 0, 0), 2)\n",
    "\n",
    "    return work_img, threshold            \n",
    "                     \n",
    "def corrfft(image1,image2):\n",
    "    image1=np.uint8(image1)\n",
    "    image2=np.uint8(image2)\n",
    "    dft1 = cv2.dft(np.float32(image1),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft2 = cv2.dft(np.float32(image2),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    corr=cv2.multiply(dft1,dft2.conj())\n",
    "    corr/=np.amax(corr)\n",
    "    #plt.figure(figsize=(15,7))\n",
    "    #plt.imshow(corr[0:1000,0:1000],cmap='gray',vmax=corr.max(),vmin=corr.min())\n",
    "    #plt.grid(True)\n",
    "    #plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    #color = 'k')   #  Цвет делений\n",
    "    \n",
    "\n",
    "from sklearn.decomposition import FastICA,PCA\n",
    "from skimage.feature import hog\n",
    "def filtration(image,path):\n",
    "    'path to file correlate'\n",
    "    'image filtration'\n",
    "    'фильтрация возвращает фильтрованное изображение'\n",
    "    imagepsnr=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    entr_img = entropy(imagepsnr, disk(1))\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(entr_img[0:1000,0:1000],cmap='gray',vmax=entr_img.max(),vmin=entr_img.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    psnr=peak_signal_noise_ratio(imagepsnr, std_convoluted(imagepsnr,2))\n",
    "    print(f'PSNR before filtration={psnr}')\n",
    "    print(f'PSNR before filtration={20*np.log10(1/imagepsnr.std())}')\n",
    "   \n",
    "    try:\n",
    "        mse = mean_squared_error(imagepsnr,imagepsnr.T)\n",
    "        print(f'PSNR before filtration={20*np.log10(1/mse)}')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "         psnr=cv2.PSNR(image, image.T)\n",
    "         print(f'PSNR before filtration={psnr}')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "     \n",
    "    print(f'PSNR before filtration max std={20*np.log10(imagepsnr.max()/imagepsnr.std())}')\n",
    "\n",
    "    \n",
    "    image=scipy.signal.wiener(image,noise=image.std())\n",
    "    \n",
    "    \n",
    "    image=np.asarray(image,dtype=np.uint8)\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    image= cv2.bilateralFilter(image,1,1,1)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_wiener.jpg\",image)\n",
    "    image=cv2.fastNlMeansDenoising(image,None,1,1,3)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_fastNlMeansDenoising.jpg\",image)\n",
    "    #image=cv2.fastNlMeansDenoising(image,None,1,1,3)\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "    clahe = cv2.createCLAHE(clipLimit=5., tileGridSize=(2,2))\n",
    "    l, a, b = cv2.split(image)\n",
    "    l2 = clahe.apply(l)  # apply CLAHE to the L-channel\n",
    "\n",
    "    lab = cv2.merge((l2,a,b))  # merge channels\n",
    "    image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    slp,hlp=sporco.signal.tikhonov_filter(image,3)\n",
    "    hlp=ndimage.median_filter(hlp, size=11)\n",
    "    hlp=hlp<np.percentile(hlp, 90)\n",
    "    image2 = readimage(path)\n",
    "    #image2=image2[0:1000,0:1000]\n",
    "    image2=np.asarray(image2,dtype=np.uint8)\n",
    "\n",
    "    mse = mean_squared_error(hlp, image2)\n",
    "    ssim = structural_similarity(hlp, image2, data_range=image2.max() - image2.min())\n",
    "    print('mse')\n",
    "    print(mse)\n",
    "    print('ssim')\n",
    "    print(ssim)\n",
    "    print()\n",
    "    print(hlp.shape)\n",
    "    print(image2.shape)\n",
    "    print()\n",
    "    image2=np.asarray(image2,dtype=np.uint8)\n",
    "    \n",
    "    #normcorr(hlp,image2)\n",
    "    res = cv2.matchTemplate(np.uint8(hlp),image2,cv2.TM_CCORR_NORMED)\n",
    "    r=cv2.cvtColor(res, cv2.COLOR_GRAY2RGB) \n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_a_normcorr2.jpg\",r)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    eng = matlab.engine.start_matlab()   \n",
    "    r=eng.corr2(hlp,image2)\n",
    "    \n",
    "    hlp=hlp-hlp.mean()-r*image2\n",
    "    try:\n",
    "        hlpf=hlp-hlp.mean()-cv2.multiply(res,image2)\n",
    "        hlpfilt=np.asarray(hlpf,dtype=np.uint8)\n",
    "        hlpfilt=cv2.cvtColor(hlpfilt,cv2.COLOR_GRAY2RGB)\n",
    "        cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_cfilt1.jpg\",hlpfilt)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    hlpfilt=np.asarray(hlp,dtype=np.uint16)\n",
    "    #hlpfilt = eng.imadjust(hlpfilt,eng.stretchlim(hlpfilt),[])\n",
    "    hlpfilt=eng.imadjust(hlpfilt)\n",
    "    hlpfilt=np.asarray(hlpfilt,dtype=np.uint8)\n",
    "    hlpfilt=cv2.cvtColor(hlpfilt,cv2.COLOR_GRAY2RGB)\n",
    "    #hlp=scipy.ndimage.percentile_filter(hlp,95)\n",
    "    \n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_cfilt.jpg\",hlpfilt)\n",
    "    #cv2.imwrite(\"C:/Users/Евгений/Downloads/s_1_1102_cfilt.jpg\",hlpfilt)\n",
    "    normcorr(hlp[0:100,0:100],image2[0:100,0:100])\n",
    "    corrfft(hlp,image2)\n",
    "    r=eng.normxcorr2(hlp,image2)\n",
    "    r=np.asarray(r,dtype=np.uint8)\n",
    "    print(r.shape)\n",
    "    \n",
    "    r=cv2.cvtColor(r, cv2.COLOR_GRAY2RGB) \n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_a_normxcorr2.jpg\",r)\n",
    "    #cv2.imwrite(\"C:/Users/Евгений/Downloads/s_1_1102_c_a_normxcorr2.jpg\",r)\n",
    "    eng.quit()\n",
    "    hlpfilt=cv2.cvtColor(hlpfilt,cv2.COLOR_RGB2GRAY)\n",
    "    imageh=hessian(hlpfilt)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(imageh[0:1000,0:1000],cmap='gray',vmax=imageh.max(),vmin=imageh.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    r=cv2.cvtColor(np.uint8(imageh), cv2.COLOR_GRAY2RGB) \n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_hessian.jpg\",r)\n",
    "    try:\n",
    "        im=cv2.cvtColor(np.uint8(image), cv2.COLOR_GRAY2RGB) \n",
    "        fd, hog_image = hog(im, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualize=True, channel_axis=-1)\n",
    "        cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_hog.jpg\",hog_image)\n",
    "    except:\n",
    "        pass\n",
    "    sigma_est =skimage.restoration.estimate_sigma(hlpfilt)\n",
    "    imagew=skimage.restoration.denoise_wavelet(hlpfilt,sigma=sigma_est)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(imagew[0:1000,0:1000],cmap='gray',vmax=imagew.max(),vmin=imagew.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    psnr=peak_signal_noise_ratio(hlpfilt, std_convoluted(hlpfilt,2))\n",
    "    print(f'PSNR after filtration={psnr}')\n",
    "    print(f'PSNR after filtration={20*np.log10(1/hlpfilt.std())}')\n",
    "    try:\n",
    "        mse = mean_squared_error(hlpfilt,hlpfilt.T)\n",
    "        print(f'PSNR after filtration={20*np.log10(1/mse)}')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        psnr=cv2.PSNR(hlpfilt,hlpfilt.T)\n",
    "        print(f'PSNR after filtration={psnr}')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(f'PSNR after filtration max std={20*np.log10(hlpfilt.max()/hlpfilt.std())}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    entr_img = entropy(hlpfilt, disk(1))\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(hlpfilt[0:1000,0:1000],cmap='gray',vmax=hlpfilt.max(),vmin=hlpfilt.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "\n",
    "    return hlpfilt\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def get_model(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "def detect_ridges(gray, sigma=1.0):\n",
    "    #hxx, hyy, hxy = hessian_matrix(gray, sigma)\n",
    "    H_elems = hessian_matrix(gray, sigma)\n",
    "    #i1, i2 = hessian_matrix_eigvals(hxx, hxy, hyy)\n",
    "    i1=hessian_matrix_eigvals(H_elems)[0]\n",
    "    i2=hessian_matrix_eigvals(H_elems)[1]\n",
    "    return i1, i2\n",
    "\n",
    "\n",
    "def ridgedetect(image):\n",
    "    imagemax,imagemin=detect_ridges(image, sigma=1.0)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(imagemax[0:1000,0:1000], cmap=plt.cm.gray,vmax=image.max(),vmin=image.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(imagemin[0:1000,0:1000], cmap=plt.cm.gray,vmax=image.max(),vmin=image.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    try:\n",
    "       ridge_filter = cv2.ximgproc.RidgeDetectionFilter_create()\n",
    "       ridges = ridge_filter.getRidgeFilteredImage(image)\n",
    "       plt.figure(figsize=(15, 7))\n",
    "       plt.imshow(ridges[0:1000,0:1000], cmap=plt.cm.gray,vmax=image.max(),vmin=image.min())\n",
    "       plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "def segmentationimage(edges):\n",
    "    # Free up RAM in case the model definition cells were run multiple times\n",
    "    keras.backend.clear_session()\n",
    "    r=cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "    # Build model\n",
    "    model = get_model(r.size, 3)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "    callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"C:/Users/evgen/Downloads/segmentation.h5\", save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    # Train the model, doing validation at the end of each epoch.\n",
    "    epochs = 5\n",
    "    model.fit(r, epochs=epochs, validation_data=r, callbacks=callbacks)\n",
    "    val_preds = model.predict(r)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(val_preds[0:1000,0:1000],cmap='gray',vmax=val_preds.max(),vmin=val_preds.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    mask = np.argmax(val_preds, axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    img = ImageOps.autocontrast(keras.utils.array_to_img(mask))\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(img[0:1000,0:1000],cmap='gray',vmax=img.max(),vmin=img.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "\n",
    "\n",
    "from scipy import special\n",
    "import pylab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import filters\n",
    "from scipy import ndimage\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "def findcountur(image):\n",
    "    contours = measure.find_contours(image, 0.8)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(image[0:1000,0:1000], cmap=plt.cm.gray,vmax=image.max(),vmin=image.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    for contour in contours:\n",
    "        plt.plot(contour[0:1000, 1], contour[0:1000, 0], linewidth=2)\n",
    "        plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "        \n",
    "    light_white =(255, 255, 247)\n",
    "    dark_white = (225, 217, 209)\n",
    "    imagergb= cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "    mask_white = cv2.inRange(imagergb, light_white, dark_white)\n",
    "    result = cv2.bitwise_and(imagergb, imagergb, mask=mask_white)\n",
    "    result= cv2.cvtColor(result,cv2.COLOR_RGB2GRAY)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(result[0:1000,0:1000],cmap='gray',vmax=result.max(),vmin=result.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    coordinates = peak_local_max(image, min_distance=2)\n",
    "    xcentrmax=coordinates[:,1]\n",
    "    ycentrmax=coordinates[:,0]\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(image, cmap=plt.cm.gray,vmax=image.max(),vmin=image.min())\n",
    "    plt.plot(coordinates[:, 1], coordinates[:, 0], 'r.')\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "\n",
    "    print('Количество локальных максимумов')\n",
    "    print(len(xcentrmax))\n",
    "\n",
    "\n",
    "    thresholds = filters.threshold_multiotsu(image, classes=3)\n",
    "    regions = np.digitize(image, bins=thresholds)\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(regions[0:1000,0:1000],cmap='gray',vmax=regions.max(),vmin=regions.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "\n",
    "    localmax=ndimage.maximum_filter(image, size=2)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(localmax[0:1000,0:1000],cmap='gray',vmax=localmax.max(),vmin=localmax.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    localmin=ndimage.minimum_filter(image, size=2)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(localmin[0:1000,0:1000],cmap='gray',vmax=localmin.max(),vmin=localmin.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    thresholds = filters.threshold_multiotsu(image, classes=3)\n",
    "    regions = np.digitize(image, bins=thresholds)\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(regions[0:1000,0:1000],cmap='gray',vmax=regions.max(),vmin=regions.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "\n",
    "    localmax=ndimage.maximum_filter(image, size=2)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(localmax[0:1000,0:1000],cmap='gray',vmax=localmax.max(),vmin=localmax.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    localmin=ndimage.minimum_filter(image, size=2)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(localmin[0:1000,0:1000],cmap='gray',vmax=localmin.max(),vmin=localmin.min())\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "\n",
    "\n",
    "def countourfind(image):\n",
    "    imagesource=image\n",
    "    'поиск контуров'\n",
    "    edges = cv2.Canny(image=image, threshold1=1, threshold2=2)\n",
    "   \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(edges[0:1000,0:1000],cmap='gray',vmax=edges.max(),vmin=edges.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    x_train=np.asarray(edges,dtype=float)\n",
    "       \n",
    "       \n",
    "    encoding_dim =8192\n",
    "       \n",
    "    input = keras.Input(shape=(image.shape[1],))\n",
    "    encoded = keras.layers.Dense(encoding_dim, activation='relu')(input)\n",
    "    decoded = keras.layers.Dense(image.shape[1], activation='relu')(encoded)\n",
    "       \n",
    "    # his model maps an input to its reconstruction\n",
    "    autoencoder = keras.Model(input, decoded)\n",
    "    autoencoder.summary()\n",
    "    autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "    autoencoder.fit(x_train, x_train,epochs=20,batch_size=512)\n",
    "    edges=autoencoder.predict(x_train)\n",
    "    edges=np.asarray(edges,dtype=np.uint8)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(edges[0:1000,0:1000],cmap='gray',vmax=edges.max(),vmin=edges.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    r=cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_edges.jpg\",r)\n",
    "    #cv2.imwrite(\"C:/Users/Евгений/Downloads/s_1_1102_c_edges.jpg\",r)\n",
    "    ret, thresh = cv2.threshold(edges, 1, 2, 0)\n",
    "    r=cv2.cvtColor(thresh,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_countour_thresh.jpg\",r)\n",
    "    thresh1=cv2.adaptiveThreshold(edges,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV, 3, 1)\n",
    "    r=cv2.cvtColor(thresh1,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_countour_threshadapt.jpg\",r)\n",
    "    contours1, hierarchy1 = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    xcentra=[]\n",
    "    ycentra=[]\n",
    "    areasa=[]\n",
    "    perimetersa = []\n",
    "    for i in contours1:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            xcentra.append(cx)\n",
    "            ycentra.append(cy)\n",
    "        areasa.append(cv2.contourArea(i))\n",
    "        perimetersa.append(cv2.arcLength(i,True))\n",
    "\n",
    "    print('Количество')\n",
    "    print(len(xcentra))\n",
    "    print()\n",
    "    d={'xcentr':xcentra,'ycentr':ycentra}\n",
    "     \n",
    "    df=pd.DataFrame(data=d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.to_csv(\"C:/Users/evgen/Downloads/contourafterfiltrationadapt.csv\")\n",
    "    df.to_excel(\"C:/Users/evgen/Downloads/contourafterfiltrationadapt.xlsx\")\n",
    "    d={'areas': areasa,'perimeters':perimetersa}\n",
    "    df=pd.DataFrame(data=d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.to_csv(\"C:/Users/evgen/Downloads/contourafterfiltrationadaptarp.csv\")\n",
    "    df.to_excel(\"C:/Users/evgen/Downloads/contourafterfiltrationadaptarp.xlsx\")\n",
    "\n",
    "    r=cv2.cvtColor(thresh,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_countour_thresh.jpg\",r)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    xcentr=[]\n",
    "    ycentr=[]\n",
    "    xcentrrect=[]\n",
    "    ycentrrect=[]\n",
    "    areas=[]\n",
    "    perimeters = []\n",
    "    mask=np.zeros_like(imagesource,dtype=np.uint8)\n",
    "    #print(mask.shape)\n",
    "    sumpixel=[]\n",
    "    #print(image.shape)\n",
    "    image= cv2.cvtColor(imagesource,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    #print(image.dtype)\n",
    "    #print(image.shape)\n",
    "    hsl=cv2.cvtColor(np.uint8(image),cv2.COLOR_RGB2HLS)\n",
    "    h1,s1,l1=cv2.split(hsl)\n",
    "    hsv=cv2.cvtColor(np.uint8(image),cv2.COLOR_RGB2HSV)\n",
    "    h2,s2,v=cv2.split(hsv)\n",
    "    lab=cv2.cvtColor(np.uint8(image),cv2.COLOR_RGB2LAB)\n",
    "    l3,a,b=cv2.split(lab)\n",
    "    lcenters1=[]\n",
    "    hcenters1=[]\n",
    "    vcenters=[]\n",
    "    scenters1=[]\n",
    "    lcenters2=[]\n",
    "    hcenters2=[]\n",
    "    lcenters3=[]\n",
    "    acenters=[]\n",
    "    bcenters=[]\n",
    "    sumpixelrect=[]\n",
    "    sumpixel=[]\n",
    "    meanpixel=[]\n",
    "\n",
    "    \n",
    "    for i in contours:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            xcentr.append(cx)\n",
    "            ycentr.append(cy)\n",
    "            lcenters1.append(l1[cy,cx])\n",
    "            #lcenters2.append(l2[cy,cx])\n",
    "            #lcenters3.append(l3[cy,cx])\n",
    "            hcenters1.append(h1[cy,cx])\n",
    "            #hcenters2.append(h2[cy,cx])\n",
    "            #hcenters2.append(h2[cy,cx])\n",
    "            acenters.append(a[cy,cx])\n",
    "            bcenters.append(b[cy,cx])\n",
    "            vcenters.append(v[cy,cx])\n",
    "        (x,y), (width, height), angle= cv2.minAreaRect(i)\n",
    "        rect=cv2.minAreaRect(i)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        xcentrrect.append(x)\n",
    "        ycentrrect.append(y)\n",
    "        areas.append(cv2.contourArea(i))\n",
    "        perimeters.append(cv2.arcLength(i,True))\n",
    "        imagefill=cv2.fillPoly(mask, i, 1)\n",
    "        #print(imagefill.shape)\n",
    "        masked_image = cv2.bitwise_and(imagefill,imagesource)\n",
    "        meanpixel.append(cv2.mean(masked_image))\n",
    "        #m,s=cv2.meanStdDev(masked_image)\n",
    "        sumpixel.append(np.sum(masked_image))\n",
    "        box = np.int0(box)\n",
    "        masked_imagerect=cv2.bitwise_and(cv2.rectangle(mask,box[2],box[3],1, 1),imagesource)\n",
    "        sumpixelrect.append(np.sum(masked_imagerect))\n",
    "        \n",
    "        \n",
    "    print('Количество')\n",
    "    print(len(xcentr))\n",
    "    print()\n",
    "        \n",
    "        \n",
    "    d={'xcentr':xcentr,'ycentr':ycentr}\n",
    "       \n",
    "    df=pd.DataFrame(data=d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.to_csv(\"C:/Users/evgen/Downloads/contourafterfiltration.csv\")\n",
    "    df.to_excel(\"C:/Users/evgen/Downloads/contourafterfiltration.xlsx\")  \n",
    "    \n",
    "    d={'areas': areas,'perimeters':perimeters}\n",
    "    df=pd.DataFrame(data=d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.to_csv(\"C:/Users/evgen/Downloads/contourafterfiltrationarp.csv\")\n",
    "    df.to_excel(\"C:/Users/evgen/Downloads/contourafterfiltrationarp.xlsx\") \n",
    "    \n",
    "    d={'lightness ':lcenters1,'value ': vcenters,'Saturation':scenters1,'hue':hcenters1,'bcenters':bcenters,'acenters':acenters}\n",
    "    df=pd.DataFrame(data=d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.to_csv(\"C:/Users/evgen/Downloads/contourafterfiltrationhsvl.csv\")\n",
    "    df.to_excel(\"C:/Users/evgen/Downloads/contourafterfiltrationhvsl.xlsx\") \n",
    "    \n",
    "    d={'xcentrrect':xcentrrect,'ycentrrect':ycentrrect}\n",
    "    df=pd.DataFrame(data=d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.to_csv(\"C:/Users/evgen/Downloads/contourafterfiltrationrect.csv\")\n",
    "    df.to_excel(\"C:/Users/evgen/Downloads/contourafterfiltrationrect.xlsx\") \n",
    "    \n",
    "    d={'meanpixel': meanpixel,'sumpixel':sumpixel,'sumpixelrect': sumpixelrect}\n",
    "    df=pd.DataFrame(data=d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.to_csv(\"C:/Users/evgen/Downloads/contourafterfiltrationsumpixel.csv\")\n",
    "    df.to_excel(\"C:/Users/evgen/Downloads/contourafterfiltrationsumpixel.xlsx\")\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize =(15, 7))\n",
    "    plt.boxplot(sumpixelrect)\n",
    "    plt.grid(True)\n",
    "    #plt.ylim(0,100)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.hist(xcentr,bins=50,density=True,stacked=True, facecolor='r',histtype= 'bar',edgecolor='k',linewidth=2, alpha=0.75)\n",
    "    plt.grid(True)\n",
    "    #plt.ylim(0,100)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.hist(ycentr,bins=50,density=True,stacked=True, facecolor='r',histtype= 'bar',edgecolor='k',linewidth=2, alpha=0.75)\n",
    "    plt.grid(True)\n",
    "    #plt.ylim(0,100)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.hist2d(xcentr, ycentr,bins = 10, cmap =\"gray\")\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    \n",
    " \n",
    "    isClosed = True\n",
    "    image3=np.zeros((image.shape[0],image.shape[1],3))\n",
    "\n",
    "    color = (255, 255, 255)\n",
    "    image=np.asarray(image,dtype=np.uint8)\n",
    "    # Line thickness of 5 px\n",
    "    thickness = 1\n",
    " \n",
    "    # Using cv2.polylines() method\n",
    "\n",
    "\n",
    "    image4 = cv2.polylines(image3, contours,\n",
    "                      isClosed, color, thickness)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(image4[0:1000,0:1000],cmap='gray',vmax=image4.max(),vmin=image4.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_contours.jpg\",image4)\n",
    "    for i in range(len(xcentr)):\n",
    "        image5=cv2.circle(image3, (xcentr[i], ycentr[i]), 1, (255, 255, 255), -1)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_centers.jpg\",image5)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(image5[0:1000,0:1000],cmap='gray',vmax=image5.max(),vmin=image5.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    \n",
    "    image6=cv2.fillPoly(image3,contours,color)\n",
    "    cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_cluster.jpg\",image6)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(image6[0:1000,0:1000],cmap='gray',vmax=image6.max(),vmin=image6.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    image= cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "    hsl=cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    h,s,l=cv2.split(hsl)\n",
    "    \n",
    "    hsv=cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    h,s,v=cv2.split(hsv)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15,7))          #create a canvas, tell matplotlib it's 3d\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    hist, xedges, yedges = np.histogram2d(xcentr, ycentr, bins=(50,50))\n",
    "    xpos, ypos = np.meshgrid(xedges[:-1]+xedges[1:], yedges[:-1]+yedges[1:])\n",
    "\n",
    "    xpos = xpos.flatten()/2.\n",
    "    ypos = ypos.flatten()/2.\n",
    "    zpos = np.zeros_like (xpos)\n",
    "\n",
    "    dx = xedges [1] - xedges [0]\n",
    "    dy = yedges [1] - yedges [0]\n",
    "    dz = hist.flatten()\n",
    "    dz=dz/dz.sum()\n",
    "\n",
    "    cmap = cm.get_cmap('jet') # Get desired colormap - you can change this!\n",
    "    max_height = np.max(dz)   # get range of colorbars so we can normalize\n",
    "    min_height = np.min(dz)\n",
    "    # scale each z to [0,1], and get their rgb values\n",
    "    rgba = [cmap((k-min_height)/max_height) for k in dz] \n",
    "\n",
    "    ax.bar3d(xpos, ypos, zpos, dx, dy, dz, color=rgba, zsort='average')\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    eng = matlab.engine.start_matlab()\n",
    "    try:\n",
    "        image=eng.imcontour(imagesource,1)\n",
    "    except:\n",
    "        pass\n",
    "    eng.quit()\n",
    "    print('Quality')\n",
    "    xcentr=np.asarray(xcentr,dtype=float)\n",
    "    print(-10*np.log10(special.erfc(xcentr.mean()/xcentr.std())))\n",
    "    print(-10*np.log10(special.erfc(len(xcentr))))\n",
    "    print()\n",
    "    \n",
    "    session=WolframLanguageSession(\"C:/Program Files/Wolfram Research/Mathematica/12.1/WolframKernel.exe\")\n",
    "    EdgeDetect=session.function(wl.EdgeDetect)\n",
    "    try:\n",
    "        image=image[0:500,0:500]\n",
    "        imageedges=EdgeDetect(image,1)\n",
    "        cv2.imwrite(\"C:/Users/evgen/Downloads/s_1_1102_c_edgeswolfram.jpg\",imageedges)\n",
    "    except:\n",
    "        pass\n",
    "    return edges\n",
    "\n",
    "\n",
    "def findcounturnewmethod(edges):\n",
    "   \n",
    "    ret, thresh = cv2.threshold(edges, 1, 2, 0)\n",
    "    contours1, hierarchy1 = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    xcentr1=[]\n",
    "    ycentr1=[]\n",
    "    for i in contours1:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            \n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            xcentr1.append(cx)\n",
    "            ycentr1.append(cy)\n",
    "\n",
    "    d={'xcentr1':xcentr1,'ycentr1':ycentr1}\n",
    "    df=pd.DataFrame(data=d)\n",
    "    \n",
    "    df.to_csv(\"C:/Users/evgen/Downloads/contour1.csv\")\n",
    "    df.to_excel(\"C:/Users/evgen/Downloads/contour1.xlsx\") \n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    image=readimage(\"C:/Users/evgen/Downloads/s_1_1102_c.jpg\")\n",
    "    image=tiffreader(\"C:/Users/evgen/Downloads/s_1_1102_c.tif\")\n",
    "    fig,(ax1,ax2) = plt.subplots(ncols=2)\n",
    "    ax1.imshow(image,cmap='gray',vmax=image.max(),vmin=image.min())\n",
    "    ax1.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    boxplot_2d(image[0:int(image.shape[0]),:],image[:,0:int(image.shape[1])],ax=ax2, whis=1.5)\n",
    "    ax2.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    #image=readimage(\"C:/s_1_1102_c.jpg\")\n",
    "    #image=readimage(\"C:/s_1_1101_a.jpg\")\n",
    "    #image=image[0:1000,0:1000]\n",
    "    print(image.shape)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(image[0:1000,0:1000],cmap='gray',vmax=image.max(),vmin=image.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "    imageplot3d(image)\n",
    "    localstdmean(image,2)\n",
    "    image= cv2.cvtColor(np.uint8(image),cv2.COLOR_GRAY2RGB)\n",
    "    hsl=cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    Lchannel = hsl[:,:,1]\n",
    "    mask = cv2.inRange(Lchannel, 250, 255)\n",
    "    res = cv2.bitwise_and(image,image, mask= mask)\n",
    "    mask = cv2.inRange(hsl, np.array([0,250,0]), np.array([255,255,255]))\n",
    "    h,s,l=cv2.split(hsl)\n",
    "    print()\n",
    "    print(f'Hue={h.sum()}')\n",
    "    print(f'Saturation={s.sum()}')\n",
    "    print(f'Lightness ={l.sum()}')\n",
    "    print(f'Lightness min ={l.min()}')\n",
    "    print(f'Lightness max ={l.max()}')\n",
    "    print(f'Lightness mean ={l.mean()}')\n",
    "    print(f'Lightness std ={l.std()}')\n",
    "\n",
    "    \n",
    "    #print(l.shape)\n",
    "    #print(type(l))\n",
    "   \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(l[0:1000,0:1000],cmap='gray',vmax=l.max(),vmin=l.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "\n",
    "    hsv=cv2.cvtColor(np.uint8(image),cv2.COLOR_RGB2HSV)\n",
    "    h,s,v=cv2.split(hsv)\n",
    "    print(f'Hue={h.sum()}')\n",
    "    print(f'Saturation={s.sum()}')\n",
    "    print(f'Value  ={v.sum()}')\n",
    "    print(f'Value min ={v.min()}')\n",
    "    print(f'Value max ={v.max()}')\n",
    "    print(f'Value mean ={v.mean()}')\n",
    "    print(f'Value std ={v.std()}')\n",
    "    print(f'image min ={image.min()}')\n",
    "    print(f'image max ={image.max()}')\n",
    "    print(f'image mean ={image.mean()}')\n",
    "    print(f'image std ={image.std()}')\n",
    "    #print(v.shape)\n",
    "    #print(type(v))\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(v[0:1000,0:1000],cmap='gray',vmax=v.max(),vmin=v.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "\n",
    "    \n",
    "    image=filtration(image,\"C:/Users/evgen/Downloads/s_1_1101_a.jpg\")\n",
    "    #image=filtration(image,\"C:/s_1_1101_a.jpg\")\n",
    "    fig,(ax1,ax2) = plt.subplots(ncols=2)\n",
    "    ax1.imshow(image,cmap='gray',vmax=image.max(),vmin=image.min())\n",
    "    ax1.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    boxplot_2d(image[0:int(image.shape[0]),:],image[:,0:int(image.shape[1])],ax=ax2, whis=1.5)\n",
    "    ax2.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    \n",
    "\n",
    "    imageground(image)\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(image[0:1000,0:1000],cmap='gray',vmax=image.max(),vmin=image.min())\n",
    "    #plt.grid(True)\n",
    "    plt.tick_params(labelsize =20,#  Размер подписи\n",
    "                    color = 'k')   #  Цвет делений\n",
    "    edges=countourfind(image)\n",
    "    findcounturnewmethod(edges)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1a757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a82d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
